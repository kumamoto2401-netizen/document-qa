import streamlit as st
import google.generativeai as genai

# Show title and description.
st.title("ğŸ“„ Document question answering")
st.write(
    "Upload a document below and ask a question about it â€“ Gemini will answer! "
    "To use this app, you need to provide your Gemini API key. "
)

# Ask user for their Gemini API key via `st.text_input`.
# You may also store the API key in `./.streamlit/secrets.toml` using the key name "gemini_api_key".
gemini_api_key = st.secrets.get("gemini_api_key")
if not gemini_api_key:
    st.info("Please add your Gemini API key to continue.", icon="ğŸ—ï¸")
else:
    # NOTE: There is no official OpenAI Python client for Gemini. 
    # You need to use Google's generativeai client or an HTTP client for Gemini API.
    # For demonstration, we'll show a typical approach using google.generativeai
    # (You must install google-generativeai: pip install google-generativeai)


    genai.configure(api_key=gemini_api_key)

    # Let the user upload a file via `st.file_uploader`.
    uploaded_file = st.file_uploader(
        "Upload a document (.txt or .md)", type=("txt", "md")
    )

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    if uploaded_file:
        document = uploaded_file.read().decode(errors="ignore")
        st.session_state.document = document
    elif "document" not in st.session_state:
        st.session_state.document = None

    # ãƒãƒ£ãƒƒãƒˆUI
    st.write("## ãƒãƒ£ãƒƒãƒˆ")
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            st.chat_message("user").write(message["content"])
        else:
            st.chat_message("ai").write(message["content"])

    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„
    if st.session_state.document:
        user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        if user_input:
            # Gemini ã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            prompt = (
                f"ã‚ãªãŸã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n"
                f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹: {st.session_state.document}\n\n"
                f"--- ã“ã‚Œã¾ã§ã®ä¼šè©± ---\n"
            )
            # ã“ã‚Œã¾ã§ã®ä¼šè©±ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ ï¼ˆæœ€æ–°5ä»¶ã¾ã§ï¼‰
            for msg in st.session_state.chat_history[-5:]:
                role = "ãƒ¦ãƒ¼ã‚¶ãƒ¼" if msg["role"] == "user" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
                prompt += f"{role}: {msg['content']}\n"
            # ä»Šå›ã®è³ªå•
            prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ:"

            # Gemini 2.5 Flash (gemini-2.5-flash) ã§å¿œç­”
            model = genai.GenerativeModel("gemini-2.5-flash")
            response = model.generate_content(prompt)
            ai_response = response.text

            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            st.session_state.chat_history.append({"role": "ai", "content": ai_response})

            # å¿œç­”ã‚’è¡¨ç¤º
            st.chat_message("ai").write(ai_response)
    else:
        st.info("ã¾ãšãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
